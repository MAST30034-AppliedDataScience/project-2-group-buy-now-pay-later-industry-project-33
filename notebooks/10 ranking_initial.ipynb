{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/05 04:49:05 WARN Utils: Your hostname, codespaces-c6855a resolves to a loopback address: 127.0.0.1; using 10.0.0.128 instead (on interface eth0)\n",
      "24/10/05 04:49:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/05 04:49:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/05 04:49:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/10/05 04:49:06 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Initial Ranking Model\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"12g\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"16G\")\n",
    "    .config(\"spark.executor.memory\", \"16G\")\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"64MB\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to create a function that will create the initial ranking. We will use the following:\n",
    "- The earning growth rate\n",
    "- The average customer fraud probability\n",
    "- The merchant fraud probability\n",
    "- The customer retention rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want all of these values to be between 0 and 1. Then we will give them a weight and sum them up to get the final ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue Growth Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_revenue = spark.read.parquet('../data/curated/predicted_monthly_revenue.parquet')\n",
    "transactions = spark.read.parquet('../data/curated/all_details/')\n",
    "merchant_monthly = transactions.groupBy(F.date_format(F.col('order_datetime'), 'yyyy-MM'), 'merchant_abn').agg(F.sum('dollar_value'))\n",
    "merchant_monthly = merchant_monthly.withColumn('month', F.month(F.col('date_format(order_datetime, yyyy-MM)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a month since first transaction column for each merchant\n",
    "merchant_monthly = merchant_monthly.withColumn('first_transaction', F.min('date_format(order_datetime, yyyy-MM)').over(Window.partitionBy('merchant_abn')))\n",
    "merchant_monthly = merchant_monthly.withColumn('month_since_first_transaction', F.months_between(F.col('date_format(order_datetime, yyyy-MM)'), F.col('first_transaction')))\n",
    "# Get the max month since first transaction for each merchant\n",
    "max_month = merchant_monthly.groupBy('merchant_abn').agg(F.max('month_since_first_transaction').alias('max_month'))\n",
    "# max_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/05 04:49:20 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "merchant_monthly = merchant_monthly.join(max_month, 'merchant_abn')\n",
    "# Filter out the merchants with max month since first transaction less than 12\n",
    "merchant_monthly = merchant_monthly.filter(F.col('month_since_first_transaction') >= 12)\n",
    "# Filter out the last 12 months of transactions for each merchant\n",
    "merchant_monthly = merchant_monthly.filter(F.col('month_since_first_transaction') >= F.col('max_month') - 12)\n",
    "# merchant_monthly.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the monthly revenue for each merchant\n",
    "merchant_yearly = merchant_monthly.groupBy('merchant_abn').agg(F.sum('sum(dollar_value)').alias('yearly_revenue'))\n",
    "# merchant_yearly.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the predicted monthly revenue for each merchant\n",
    "summed_future_revenue = future_revenue.groupBy('merchant_abn').agg(F.sum('prediction').alias('predicted_yearly_revenue'))\n",
    "# summed_future_revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the take rate to summed future revenue\n",
    "revenue = merchant_yearly.join(summed_future_revenue, 'merchant_abn')\n",
    "# revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = revenue.distinct()\n",
    "revenue = revenue.withColumn('growth_rate', (F.col('predicted_yearly_revenue') - F.col('yearly_revenue')) / F.col('yearly_revenue'))\n",
    "# revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Fraud Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_fraud = spark.read.parquet('../data/curated/predicted_consumer_fraud/*')\n",
    "# customer_fraud.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.join(customer_fraud, 'order_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the average consumer fraud for each merchant\n",
    "merchant_agg_fraud = transactions.groupby('merchant_abn').agg(F.avg('consumer_fraud').alias('avg_consumer_fraud'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_agg_fraud.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = spark.read.parquet('../data/curated/predicted_merchant_fraud/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_abn = transactions.select('order_id', 'merchant_abn').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = merchant_fraud.join(order_abn, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the order_id column\n",
    "merchant_fraud = merchant_fraud.drop('order_id')\n",
    "# merchant_fraud.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Retention Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_retention = spark.read.parquet('../data/curated/customer_retention/*')\n",
    "# customer_retention.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the initial ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fraud = merchant_fraud.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows for each dataset before joining\n",
    "print('Number of rows in revenue:', revenue.count())\n",
    "print('Number of rows in merchant fraud:', merchant_fraud.count())\n",
    "print('Number of rows in customer retention:', customer_retention.count())\n",
    "print('Number of rows in customer fraud:', merchant_agg_fraud.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of records is same for all the datasets (4422) except for revenue dataset and merchant fraud. This is due to the fact that merchants with less than 12 months of data are not included in the revenue dataset. We will check the number of merchants in merchant fraud dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of distinct merchants in merchant_fraud\n",
    "print('Number of distinct merchants in merchant fraud:', merchant_fraud.select('merchant_abn').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the non distinct merchants in merchant_fraud\n",
    "merchant_fraud.groupBy('merchant_abn').count().filter(F.col('count') > 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values of merchant fraud for these non distinct merchants, we take the decision to take the average of the values\n",
    "merchant_fraud = merchant_fraud.groupBy('merchant_abn').agg(F.avg('merchant_fraud').alias('merchant_fraud_prediction'))\n",
    "# merchant_fraud.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights will be 0.25 for each of the four factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = revenue.join(merchant_agg_fraud, on ='merchant_abn', how = 'inner')\n",
    "ranking = ranking.join(merchant_fraud, on = 'merchant_abn', how = 'inner')\n",
    "ranking = ranking.join(customer_retention, on = 'merchant_abn', how = 'inner')\n",
    "# ranking.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Scaling growth rate score to be between 0 and 1\n",
    "min_growth_rate = ranking.agg(F.min('growth_rate')).collect()[0][0]\n",
    "max_growth_rate = ranking.agg(F.max('growth_rate')).collect()[0][0]\n",
    "ranking = ranking.withColumn('growth_rate_score', (F.col('growth_rate') - min_growth_rate) / (max_growth_rate - min_growth_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing max and min values of growth rate score, average consumer fraud, merchant fraud and returning customer proportion to check if they are between 0 and 1\n",
    "print('Max growth rate score:', ranking.agg(F.max('growth_rate_score')).collect()[0][0])\n",
    "print('Min growth rate score:', ranking.agg(F.min('growth_rate_score')).collect()[0][0])\n",
    "print('Max avg consumer fraud:', ranking.agg(F.max('avg_consumer_fraud')).collect()[0][0])\n",
    "print('Min avg consumer fraud:', ranking.agg(F.min('avg_consumer_fraud')).collect()[0][0])\n",
    "print('Max merchant fraud:', ranking.agg(F.max('merchant_fraud_prediction')).collect()[0][0])\n",
    "print('Min merchant fraud:', ranking.agg(F.min('merchant_fraud_prediction')).collect()[0][0])\n",
    "print('Max returning customer proportion:', ranking.agg(F.max('returning_customer_proportion')).collect()[0][0])\n",
    "print('Min returning customer proportion:', ranking.agg(F.min('returning_customer_proportion')).collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consumer fraud probability and merchant fraud probability is to be divided by 100 to get the values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = ranking.withColumn('final_score', (F.col('growth_rate_score') + (1-(F.col('avg_consumer_fraud')/100)) + (1-(F.col('merchant_fraud_prediction')/100)) + F.col('returning_customer_proportion'))/4)\n",
    "# ranking.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = ranking.select('merchant_abn', 'final_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking=ranking.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|merchant_abn|       final_score|\n",
      "+------------+------------------+\n",
      "| 46804135891|0.6777120982876664|\n",
      "| 63290521567|0.6749088816613451|\n",
      "| 64203420245|0.6735086366160532|\n",
      "| 49891706470|0.6734876409303723|\n",
      "| 68216911708| 0.673419306638833|\n",
      "| 45629217853|0.6733255685982173|\n",
      "| 89726005175|0.6732569639090749|\n",
      "| 80324045558|0.6729121388016536|\n",
      "| 95824231566|0.6706274916780242|\n",
      "| 21439773999|0.6700187523090408|\n",
      "| 13467303030|0.6649252706700772|\n",
      "| 72472909171|0.6622214852629547|\n",
      "| 94493496784|0.6573385083234794|\n",
      "| 79417999332|0.6566989590735425|\n",
      "| 60956456424| 0.651398243090242|\n",
      "| 32361057556|0.6484768972386095|\n",
      "| 91923722701|0.6408525833479833|\n",
      "| 64403598239|0.6365628297962749|\n",
      "| 49505931725|0.6343411880850518|\n",
      "| 48534649627|0.6314486821874987|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking.sort(F.col('final_score').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ranking.write.mode('overwrite').parquet('../data/curated/merchant_ranking/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
