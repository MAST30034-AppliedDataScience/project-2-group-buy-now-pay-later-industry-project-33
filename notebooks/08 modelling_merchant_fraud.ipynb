{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0962a4c0",
   "metadata": {},
   "source": [
    "# Modelling: merchant fraud\n",
    "In this notebook, we develop models to impute the merchant fraud rate based on current transactions and consumer ata (full dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe66e1-7315-4674-9758-d819d00848d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed479408-7035-4085-9f65-f17244fd6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data Modelling 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"10g\") \n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a3a07-623b-40e1-bac2-226c54c2d064",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d91d1-9d44-4dfb-939a-d6f53e8a292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on merchants\n",
    "merchant = spark.read.parquet(\"../data/curated/part_1/clean_merchant.parquet\")\n",
    "\n",
    "# Information on merchant's fraud probability\n",
    "merchant_fraud_prob = pd.read_csv(\"../data/tables/part_1/merchant_fraud_probability.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e565d73-dbd5-43f5-be32-cc084de87bac",
   "metadata": {},
   "source": [
    "### Preprocessing `goods` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc66497-4617-444b-99fb-a5e5740d9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, PCA, StopWordsRemover\n",
    "from pyspark.sql.functions import lower, regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c340ba2-e65c-4d05-844a-6e40bee5feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "goods = merchant.select(\"goods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5edf4c0-0301-4081-b496-11289e96490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_goods = goods.withColumn(\"str_goods\", lower(regexp_replace(\"goods\", \"[^\\w\\s]\", \"\")))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"str_goods\", outputCol=\"tokens\")\n",
    "clean_goods = tokenizer.transform(clean_goods)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"clean_goods\")\n",
    "clean_goods = remover.transform(clean_goods)\n",
    "clean_goods = clean_goods.select('clean_goods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001d388-baf6-4608-95a8-0b68b6d479a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(inputCol=\"clean_goods\", outputCol=\"features\")\n",
    "\n",
    "model = count_vectorizer.fit(clean_goods)\n",
    "result = model.transform(clean_goods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ce9f6-30ea-46a2-ac3a-46594494bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.limit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19ae3a-234a-4c44-92f2-49a7c6d53721",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=12, inputCol=\"features\")\n",
    "pca.setOutputCol(\"pca_features\")\n",
    "\n",
    "model = pca.fit(result)\n",
    "pca_result = model.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e7414-ec3e-437c-a9f6-d378b1a1e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transform(result).collect()[0].pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a1b48-ed0a-4c73-b30f-772789968d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.explainedVariance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74701863-c15d-43a5-8741-6cc7bd4c5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result = pca_result.withColumn(\"id\", monotonically_increasing_id())\n",
    "merchant = merchant.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a57587-b19d-48a1-8077-94e9003ecb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant = merchant.join(pca_result.select('pca_features', 'id'), on='id', how='inner')\n",
    "merchant = merchant.drop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45264c9-d235-49db-9cec-b222bab757ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e3e95-285c-40bf-b873-d1e7202e33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ordered categories\n",
    "ordered_categories = ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# Map the categories to their corresponding ordinal codes\n",
    "merchant = merchant.withColumn(\n",
    "    \"ordinal_revenue_level\",\n",
    "    when(F.col(\"revenue_level\") == \"a\", 0)\n",
    "    .when(F.col(\"revenue_level\") == \"b\", 1)\n",
    "    .when(F.col(\"revenue_level\") == \"c\", 2)\n",
    "    .when(F.col(\"revenue_level\") == \"d\", 3)\n",
    "    .when(F.col(\"revenue_level\") == \"e\", 4)\n",
    ")\n",
    "\n",
    "merchant = merchant.drop(\"revenue_level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbfd89-84f1-4c68-ada2-cba94de99db8",
   "metadata": {},
   "source": [
    "### Join transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc1d79-c52f-4a74-8d5b-3876c68b9830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = spark.read.parquet('../data/curated/all_details/')\n",
    "temp.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff339b2-f27a-4bd4-948d-8861743c3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = temp.join(merchant, on='merchant_abn', how='left')\n",
    "full_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4caecb-9e3e-437e-85d7-a883d8ad5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select useful columns\n",
    "merchant_is_fraud_model = full_dataset.select([\"order_id\", \"merchant_abn\", \"user_id\", \"order_datetime\", \"dollar_value\", \"postcode\", \"merchant_fraud\", \"weekly_personal_disposable\",\n",
    "                     \"median_total_household_income\", \"median_total_family_income\", \"avg_household_size\", \"median_age\", \"is_po_box\", \"ordinal_revenue_level\" ,\"take_rate\", \"pca_features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe578a4-b6c5-4f97-a637-900ed2865436",
   "metadata": {},
   "source": [
    "We check the number of Null values in merchant fraud probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5b458-3163-425c-8bf1-cd86ef1270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_is_fraud_model.filter(F.col('merchant_fraud') > 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4aa24-63e4-4d82-9501-cb08ace68c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merchant_is_fraud_model.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514fd23d-8ea2-4e7c-9804-a111b38402c0",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c454e0-d550-49bb-a79a-4bbd5f6d20ba",
   "metadata": {},
   "source": [
    "We want to check the correlation between each attribute using a subsample dataset. The subsample dataset contains 30% of the 2022 data and 70% of the 2021 data as we will train model on the data in 2021 and test it on the data in 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438de46-fb90-413e-93b0-dbdac2906ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247278cb-9b88-477d-a810-e6e4f23a834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_merchant_fraud_df = merchant_is_fraud_model.sample(0.01, seed=42).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7e648-19b8-4302-80f4-abe7a5c290e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in sample_merchant_fraud_df.columns if sample_merchant_fraud_df[col].dtype != 'object']\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(sample_merchant_fraud_df.loc[sample_merchant_fraud_df['merchant_fraud'] > 0][num_cols].corr(), annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d3a33-da16-4a65-9cb3-8201a7337ec9",
   "metadata": {},
   "source": [
    "Because pyspark ml can't handle Null values, we drop external attributes that contain Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202dd434-8b7f-498b-8e02-5960e8e8e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"order_id\", \"merchant_abn\", \"dollar_value\", \"merchant_fraud\", \"ordinal_revenue_level\" ,\"take_rate\", \"order_datetime\", \"pca_features\"]\n",
    "impute_merchant_fraud_sdf = merchant_is_fraud_model.select(selected_features)\n",
    "impute_merchant_fraud_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a568e4-ca15-448e-b8aa-4a21ea589e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_merchant_fraud_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e21420-78fe-4969-9d16-6204f5621113",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_merchant_fraud_sdf.filter(F.col(\"take_rate\").isNotNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6ba5f-724b-4cb4-9df9-6f572e4aac85",
   "metadata": {},
   "source": [
    "As we expected, there are some merchants not existing in transaction dataset, we will remove those instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf7ecc-86ae-4d3a-96d8-ac0028e90242",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_merchant_fraud_sdf = impute_merchant_fraud_sdf.filter(F.col(\"take_rate\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04682bc-4a30-4a3d-8425-9d83d98513ab",
   "metadata": {},
   "source": [
    "Let's check the number of instances with non-missing fraud probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f2caf-d64b-4bf2-bd7b-9c2d4d77b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_merchant_fraud_sdf.filter(F.col('merchant_fraud') > 0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcba3a1-bcb6-4fde-af3c-5f75a5dca405",
   "metadata": {},
   "source": [
    "We would like to use these instances to build a imputation model for the remaining null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac87b88-d55b-4a08-a875-c0ab7c3e5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = impute_merchant_fraud_sdf.filter(F.col('merchant_fraud') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfa91c-8628-41e3-a329-d9e56a2ad1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = model_df.dropna('any')\n",
    "final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c94c26-e4e0-4f28-a512-e9241e1ccce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9265549-2afa-4441-bbba-97be75c922b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to file\n",
    "final_df.write.mode('overwrite').parquet('../data/curated/modelling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52143df-e4d1-4ae9-b7c4-4a0806dcde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sdf = spark.read.parquet('../data/curated/modelling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540334e8-3417-41a8-940b-657113609665",
   "metadata": {},
   "source": [
    "## Train Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123c468-a60a-4667-8083-b0f6e651a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f236c-0ffb-42d3-b99a-0c027fe042a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = model_sdf.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e8c1c-ac74-44ec-9975-9b067b246c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387b246-deec-4584-a5c1-3a54438c82f0",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "The model only predicts the mean value for all test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee70c18-b84b-41b0-859b-29e2d57c86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = testData.agg(F.mean(\"merchant_fraud\")).collect()[0][0]\n",
    "mean_predictions_df = testData.select(\"merchant_fraud\").withColumn(\"prediction\", F.lit(mean_value))\n",
    "\n",
    "mse_evaluator = RegressionEvaluator(labelCol=\"merchant_fraud\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"merchant_fraud\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "# Get the score\n",
    "mse = mse_evaluator.evaluate(mean_predictions_df)\n",
    "mae = mae_evaluator.evaluate(mean_predictions_df)\n",
    "\n",
    "print(f\"Mean Square Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53420465-c6c8-47d7-9023-95df04d43e39",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "We aim to create a simple model, therefore, the model hyperparameters were chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea6991-de25-449a-9fa5-f15230bed45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4caf3c-eca9-4b37-bf85-febf7b6c628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'features'\n",
    "input_cols = trainingData.drop('merchant_fraud').drop('order_id').drop('order_datetime').drop('merchant_abn').columns\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    # which column to combine\n",
    "    inputCols=input_cols, \n",
    "    # How should the combined columns be named\n",
    "    outputCol=features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92058f50-ea91-4ced-87b8-24e14a35fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rft = RandomForestRegressor(\n",
    "    featuresCol='features', \n",
    "    labelCol='merchant_fraud',\n",
    "    numTrees=5, \n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5380db-e74c-47b5-9b02-092f066a3ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, rft])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46171939-ce99-4fbe-9906-6f5f7a1ecfd1",
   "metadata": {},
   "source": [
    "- Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b57892-ee41-4140-84f2-82147383c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411fa77-cc91-4059-ad72-63b3ecdf24d7",
   "metadata": {},
   "source": [
    "- Evaluate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da52c3-6474-4177-b78a-ff1c953d3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_evaluator = RegressionEvaluator(labelCol=\"merchant_fraud\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mae_evaluator = RegressionEvaluator(labelCol=\"merchant_fraud\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "# Get the score\n",
    "mse = mse_evaluator.evaluate(predictions)\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Mean Square Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b012b-7526-4766-9cd2-ff53d5435572",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd = predictions.select(\"prediction\", \"merchant_fraud\").toPandas()\n",
    "plt.scatter(result_pd.merchant_fraud, result_pd.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be67bf2-6013-4b56-ab84-e6b9a3348dfd",
   "metadata": {},
   "source": [
    "### Imputation for merchant fraud probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5475e-7360-4a6e-9f53-4a0915493252",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_data = impute_merchant_fraud_sdf.filter(F.col('merchant_fraud') == 0).drop('merchant_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dff9ae-a707-4f4f-858b-586adcfdf3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_sdf = model.transform(imputation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a26fd5-147a-42ac-a9fc-1563eb554081",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_sdf.select(\"prediction\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6b5dd-fabe-404e-95d3-8ae2f1577a03",
   "metadata": {},
   "source": [
    "We merge imputed merchant fraud probability to the main dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe522fc4-078e-429e-8efe-75ce7253611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with given merchant fraud probability\n",
    "non_missing_merchant_fraud = model_sdf.select([\"order_id\", \"merchant_fraud\"])\n",
    "imputed_sdf_select = imputed_sdf.select([\"order_id\", \"prediction\"]).withColumnRenamed(\"prediction\", \"merchant_fraud\")\n",
    "\n",
    "# Combine two dataset\n",
    "full_merchant_fraud = imputed_sdf_select.union(non_missing_merchant_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2c8e7-b296-4f1b-a045-2294bb4882e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to file\n",
    "full_merchant_fraud.write.mode('overwrite').parquet('../data/curated/predicted_merchant_fraud/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54ac6a-aae4-40f0-9026-1863a497d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.parquet('../data/curated/predicted_merchant_fraud/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7fd4e-b807-46ff-a059-64fc85bdf726",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697cb36-7130-4347-9bda-23d832508180",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.limit(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
