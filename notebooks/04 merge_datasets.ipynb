{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join customer/merchant/transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/05 04:34:03 WARN Utils: Your hostname, codespaces-c6855a resolves to a loopback address: 127.0.0.1; using 10.0.0.128 instead (on interface eth0)\n",
      "24/10/05 04:34:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/05 04:34:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/05 04:34:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 49590)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data Joining\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"9g\") \n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/05 04:34:21 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Load in datasets\n",
    "# Load in merchant data (parquet)\n",
    "merchant = spark.read.parquet(\"../data/curated/part_1/clean_merchant.parquet\")\n",
    "\n",
    "# Load in merchant fraud (csv)\n",
    "merchant_fp = pd.read_csv(\"../data/tables/part_1/merchant_fraud_probability.csv\")\n",
    "merchant_fp = spark.createDataFrame(merchant_fp)\n",
    "\n",
    "# Load in consumer list (csv)\n",
    "consumer_cid = pd.read_csv(\"../data/tables/part_1/tbl_consumer.csv\", delimiter=\"|\")\n",
    "consumer_cid = spark.createDataFrame(consumer_cid)\n",
    "\n",
    "# Load in consumer fraud (csv)\n",
    "consumer_fp = pd.read_csv(\"../data/tables/part_1/consumer_fraud_probability.csv\")\n",
    "consumer_fp = spark.createDataFrame(consumer_fp)\n",
    "\n",
    "consumer_ud = spark.read.parquet(\"../data/tables/part_1/consumer_user_details.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join customer data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining user id to customers\n",
    "consumer_cid = consumer_cid.withColumn(\"postcode\", consumer_cid.postcode.cast('string')) # cast postcode to string\n",
    "consumer = consumer_cid.join(consumer_ud, on = \"consumer_id\", how = 'left')\n",
    "consumer_list = consumer.select(\"user_id\", \"postcode\")\n",
    "consumer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join customers and transaction data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read transaction dataset\n",
    "transaction1 = spark.read.parquet(\"../data/tables/part_2\")\n",
    "transaction2 = spark.read.parquet(\"../data/tables/part_3\")\n",
    "transaction3 = spark.read.parquet(\"../data/tables/part_4\")\n",
    "\n",
    "transaction = transaction1.union(transaction2).union(transaction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join customers to transactions\n",
    "transaction_consumer = transaction.join(consumer_list, on='user_id', how='left')\n",
    "transaction_consumer.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_no_transaction = consumer_list.join(transaction, on='user_id', how='left_anti')\n",
    "print(f\"Number of consumers that have not made a transaction: {consumer_no_transaction.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining customer transaction to merchant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for any multiple entries in consumer_fp\n",
    "consumer_fp = consumer_fp.groupBy('order_datetime', 'user_id').agg(F.max('fraud_probability').alias('fraud_probability'))\n",
    "\n",
    "# Add consumer fraud to transactions\n",
    "final_df = transaction_consumer.join(consumer_fp, on=['order_datetime', 'user_id'], how='left').withColumnRenamed('fraud_probability', 'consumer_fraud')\n",
    "no_fraud = final_df.filter(F.col(\"consumer_fraud\").isNull()).count()\n",
    "print(f\"Number of transactions with no consumer fraud: {no_fraud:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for any multiple entries in merchant_fp\n",
    "merchant_fp = merchant_fp.groupBy('order_datetime', 'merchant_abn').agg(F.max('fraud_probability').alias('fraud_probability'))\n",
    "\n",
    "# Add merchant fraud to transactions by merchant and date\n",
    "final_df = final_df.join(merchant_fp, on=['merchant_abn','order_datetime'], how = 'left').withColumnRenamed('fraud_probability', 'merchant_fraud')\n",
    "no_fraud = final_df.filter(F.col(\"merchant_fraud\").isNull()).count()\n",
    "print(f\"Number of transactions with no merchant fraud: {no_fraud:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute all null fraud probabilities as 0\n",
    "final_df = final_df.fillna(0, subset=['merchant_fraud', 'consumer_fraud'])\n",
    "no_fraud = final_df.filter((final_df[\"consumer_fraud\"]==0) & (final_df[\"merchant_fraud\"]==0)).count()\n",
    "print(f\"Number of transactions with no merchant fraud or consumer fraud: {no_fraud:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/05 04:35:43 WARN TaskSetManager: Stage 12 contains a task of very large size (6923 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save transaction-merchant-consumer data to file\n",
    "final_df.write.mode('overwrite').parquet('../data/curated/fraud_watch/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join external datasets\n",
    "Here, we estimate weekly disposible income based on the difference between total_personal_income and the average spent on rent or morgage repayments per week. The calculation uses weekly variables as follows.\n",
    "$$\\text{weekly disposible income} = \\text{total personal income} - (\\text{median rent} \\times \\text{proportion of renters}) - (\\text{median morgage repayment} \\times \\text{proportion of mortgage holders})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TENLLD</th>\n",
       "      <th>sa2_code</th>\n",
       "      <th>owned_outright</th>\n",
       "      <th>owned_mortgage</th>\n",
       "      <th>renting</th>\n",
       "      <th>total_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101021007</td>\n",
       "      <td>1707</td>\n",
       "      <td>1092</td>\n",
       "      <td>497</td>\n",
       "      <td>3438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101021008</td>\n",
       "      <td>1789</td>\n",
       "      <td>2469</td>\n",
       "      <td>1756</td>\n",
       "      <td>6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101021009</td>\n",
       "      <td>2220</td>\n",
       "      <td>3098</td>\n",
       "      <td>4238</td>\n",
       "      <td>9842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101021010</td>\n",
       "      <td>1040</td>\n",
       "      <td>1426</td>\n",
       "      <td>1973</td>\n",
       "      <td>4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101021012</td>\n",
       "      <td>2455</td>\n",
       "      <td>4055</td>\n",
       "      <td>1972</td>\n",
       "      <td>8608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "TENLLD   sa2_code  owned_outright  owned_mortgage  renting  total_responses\n",
       "0       101021007            1707            1092      497             3438\n",
       "1       101021008            1789            2469     1756             6150\n",
       "2       101021009            2220            3098     4238             9842\n",
       "3       101021010            1040            1426     1973             4549\n",
       "4       101021012            2455            4055     1972             8608"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download housing data\n",
    "file_path = '../data/tables/sa2_dataset/main/C21_G37_SA2.csv'\n",
    "url = \"https://api.data.abs.gov.au/data/C21_G37_SA2/1+2+R_T+_T...SA2..2021.?detail=full\"\n",
    "headers = {'accept': 'text/csv'}\n",
    "\n",
    "# Request data\n",
    "response = requests.get(url, headers=headers, stream=True)\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            file.write(chunk)\n",
    "\n",
    "# Read in data and cast types\n",
    "data = pd.read_csv(file_path, dtype={\"REGION\": object})\n",
    "\n",
    "variables = {\"R_T\":'renting',\n",
    "             \"2\":'owned_mortgage',\n",
    "             \"1\": 'owned_outright',\n",
    "             \"_T\":'total_responses',\n",
    "             \"REGION\": 'sa2_code'}\n",
    "\n",
    "# Aggregate to ignore the 'dwelling type' feature\n",
    "tenure_data = data.groupby(['REGION', 'TENLLD']).agg('sum').reset_index()[['REGION', 'TENLLD', 'OBS_VALUE']]\n",
    "tenure_data = tenure_data.pivot(index='REGION', columns='TENLLD', values='OBS_VALUE').reset_index()\n",
    "tenure_data = tenure_data.rename(variables, axis=1)\n",
    "tenure_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SA2 zones with no data from ABS:  67\n"
     ]
    }
   ],
   "source": [
    "# Apply calculations\n",
    "tenure_data['percent_mortgage'] = tenure_data['owned_mortgage'] / tenure_data['total_responses']\n",
    "tenure_data['percent_rent'] = tenure_data['renting'] / tenure_data['total_responses']\n",
    "\n",
    "# Investigate number of records with missing data\n",
    "zero_responses = tenure_data[tenure_data.isna().any(axis=1)]\n",
    "print('Number of SA2 zones with no data from ABS: ', len(zero_responses))\n",
    "zero_responses.head(5)\n",
    "\n",
    "# Handle missing null values by setting to zero\n",
    "percentage_tenure = tenure_data.fillna(0, axis=1).iloc[:,[0, -1, -2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa2_code</th>\n",
       "      <th>median_age</th>\n",
       "      <th>median_total_personal_income</th>\n",
       "      <th>median_total_family_income</th>\n",
       "      <th>median_total_household_income</th>\n",
       "      <th>median_mortgage_repayment</th>\n",
       "      <th>median_rent</th>\n",
       "      <th>avg_people_per_bedroom</th>\n",
       "      <th>avg_household_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101021007</td>\n",
       "      <td>51.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101021008</td>\n",
       "      <td>38.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101021009</td>\n",
       "      <td>37.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sa2_code  median_age  median_total_personal_income  \\\n",
       "0  101021007        51.0                         760.0   \n",
       "1  101021008        38.0                         975.0   \n",
       "2  101021009        37.0                         996.0   \n",
       "\n",
       "   median_total_family_income  median_total_household_income  \\\n",
       "0                      1886.0                         1429.0   \n",
       "1                      2334.0                         1989.0   \n",
       "2                      2233.0                         1703.0   \n",
       "\n",
       "   median_mortgage_repayment  median_rent  avg_people_per_bedroom  \\\n",
       "0                     1732.0        330.0                     0.8   \n",
       "1                     1950.0        350.0                     0.8   \n",
       "2                     1700.0        330.0                     0.9   \n",
       "\n",
       "   avg_household_size  \n",
       "0                 2.2  \n",
       "1                 2.6  \n",
       "2                 2.1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in dataset with median statistics\n",
    "variables = {1: \"median_age\", \n",
    "             2: \"median_total_personal_income\",\n",
    "             3: \"median_total_family_income\",\n",
    "             4: \"median_total_household_income\",\n",
    "             5: \"median_mortgage_repayment\",\n",
    "             6: \"median_rent\",\n",
    "             7: \"avg_people_per_bedroom\",\n",
    "             8: \"avg_household_size\"}\n",
    "\n",
    "# Read in data\n",
    "medians = pd.read_csv(\"../data/curated/sa2_dataset/C21_G02_SA2_clean.csv\")\n",
    "\n",
    "# Restructure table\n",
    "medians = medians.pivot(index='sa2_code', columns=['type_of_value_code'], values='obs_value').reset_index().rename(columns=variables)\n",
    "medians.columns.name = None\n",
    "medians['sa2_code'] = medians.sa2_code.astype(str)\n",
    "medians.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before joining housing data to this table of medians, we investigate the records and notice that there are records that have null median summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_NAME_2021</th>\n",
       "      <th>POSTCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No usual address (NSW)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No usual address (Vic.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No usual address (Qld)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No usual address (SA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No usual address (WA)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No usual address (Tas.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No usual address (NT)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No usual address (ACT)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No usual address (OT)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SA2_NAME_2021 POSTCODE\n",
       "0   No usual address (NSW)      NaN\n",
       "1  No usual address (Vic.)      NaN\n",
       "2   No usual address (Qld)      NaN\n",
       "3    No usual address (SA)      NaN\n",
       "4    No usual address (WA)      NaN\n",
       "5  No usual address (Tas.)      NaN\n",
       "6    No usual address (NT)      NaN\n",
       "7   No usual address (ACT)      NaN\n",
       "8    No usual address (OT)      NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in list of SA2 codes and associated names\n",
    "col_types = {\"POSTCODE\": str, \"SA2_CODE_2021\":str, \"RATIO_FROM_TO\": float}\n",
    "sa2_names = pd.read_excel(\"../data/tables/correspondence/CG_POSTCODE_2021_SA2_2021.xlsx\", converters=col_types)[['SA2_CODE_2021', 'SA2_NAME_2021', 'POSTCODE']]\n",
    "\n",
    "# Find records with null columns\n",
    "null_regions = medians[medians.isna().any(axis=1)]\n",
    "null_regions = null_regions.merge(sa2_names, left_on='sa2_code', right_on='SA2_CODE_2021')\n",
    "\n",
    "# Show the name of regions associated with null values \n",
    "null_regions.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the external dataset is only missing values for SA2 regions marked as having \"no usual address\", and this is ok since they are special purpose codes that don't correspond with a SA2 zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>sa2_code</th>\n",
       "      <th>sa2_name</th>\n",
       "      <th>median_age</th>\n",
       "      <th>median_total_family_income</th>\n",
       "      <th>median_total_household_income</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>weekly_personal_disposable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0800</td>\n",
       "      <td>701011002</td>\n",
       "      <td>Darwin City</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2403.0</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>836.772739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0810</td>\n",
       "      <td>701021021</td>\n",
       "      <td>Lyons (NT)</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2981.0</td>\n",
       "      <td>2965.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>980.881015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0812</td>\n",
       "      <td>701021019</td>\n",
       "      <td>Karama</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>547.723664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0820</td>\n",
       "      <td>701011008</td>\n",
       "      <td>Stuart Park</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>890.395423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  postcode   sa2_code     sa2_name  median_age  median_total_family_income  \\\n",
       "0     0800  701011002  Darwin City        33.0                      2403.0   \n",
       "1     0810  701021021   Lyons (NT)        30.0                      2981.0   \n",
       "2     0812  701021019       Karama        35.0                      2021.0   \n",
       "3     0820  701011008  Stuart Park        34.0                      2682.0   \n",
       "\n",
       "   median_total_household_income  avg_household_size  \\\n",
       "0                         2151.0                 2.0   \n",
       "1                         2965.0                 3.3   \n",
       "2                         1783.0                 2.9   \n",
       "3                         2278.0                 2.3   \n",
       "\n",
       "  weekly_personal_disposable  \n",
       "0                 836.772739  \n",
       "1                 980.881015  \n",
       "2                 547.723664  \n",
       "3                 890.395423  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEEKS_IN_MONTH = 4.345\n",
    "\n",
    "# Add engineered housing features to ABS demographic data\n",
    "abs_df = medians.merge(percentage_tenure, on='sa2_code')\n",
    "\n",
    "# Calculate average weekly spending on housing per SA2 zone\n",
    "# note: monthly mortgage repayment converted to weekly by dividing by # weeks in a month\n",
    "abs_df['avg_housing_weekly'] = abs_df.median_rent*abs_df.percent_rent + abs_df.median_mortgage_repayment*(abs_df.percent_mortgage/WEEKS_IN_MONTH)\n",
    "abs_df['weekly_personal_disposable'] = abs_df.median_total_personal_income - abs_df.avg_housing_weekly\n",
    "\n",
    "# Associate postcodes to SA2 data using \"correspondence.parquet\"\n",
    "sa2_names = pd.read_parquet('../data/curated/correspondence.parquet')\n",
    "abs_df = sa2_names.merge(abs_df, on='sa2_code', how='left')\n",
    "\n",
    "# Remove unecessary columns\n",
    "abs_df = abs_df.drop(['median_mortgage_repayment', 'median_rent', 'percent_rent', \n",
    "                      'percent_mortgage', 'avg_housing_weekly', \n",
    "                      'median_total_personal_income', 'avg_people_per_bedroom'], axis=1)\n",
    "abs_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "abs_df.to_parquet('../data/curated/sa2_dataset/abs_medians.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join ABS and customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': 'count',\n",
       " 'postcode': '14195505',\n",
       " 'merchant_abn': '14195505',\n",
       " 'user_id': '14195505',\n",
       " 'dollar_value': '14195505',\n",
       " 'order_id': '14195505',\n",
       " 'consumer_fraud': '14195505',\n",
       " 'merchant_fraud': '14195505',\n",
       " 'sa2_code': '11715485',\n",
       " 'sa2_name': '11715485',\n",
       " 'median_age': '11715485',\n",
       " 'median_total_family_income': '11715485',\n",
       " 'median_total_household_income': '11715485',\n",
       " 'avg_household_size': '11715485',\n",
       " 'weekly_personal_disposable': '11715485'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in abs demographic data and customer/transaction data\n",
    "abs_df = spark.read.parquet(\"../data/curated/sa2_dataset/abs_medians.parquet\")\n",
    "\n",
    "try:\n",
    "    final_df = spark.read.parquet(\"../data/curated/fraud_watch\")\n",
    "except:\n",
    "    final_df = final_df\n",
    "\n",
    "# Join ABS data to transactions records\n",
    "customer_details_abs = final_df.join(abs_df, on='postcode', how='left')\n",
    "\n",
    "# Check NULL values for transaction data\n",
    "customer_details_abs.summary('count').toPandas().to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are some customer records that are to locations that have no population data. Many of these postcodes are for PO boxes and LVR addresses. For this, we create another field `is_po_box` to help filter out transactions to users delivering to special postcodes.\n",
    "\n",
    "The ranges for LVRs and PO Boxes were sourced from [Matthew Procter's Australian Postcodes website](https://www.matthewproctor.com/australian_postcodes#downloadlinks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deine PO/LVR range\n",
    "po_box_codes = [(\"1000\", \"1999\"), (\"0200\", \"0299\"), (\"8000\", \"8999\"),\n",
    "                (\"9000\", \"9999\"), (\"5800\", \"5999\"), (\"6800\", \"6999\"),\n",
    "                (\"7800\", \"7999\"), (\"0900\", \"0999\")]\n",
    "\n",
    "# Determine if postcode is in a PO box/LVR range\n",
    "po_box_condition = F.lit(False)\n",
    "for lower, upper in po_box_codes:\n",
    "    po_box_condition = po_box_condition | ((F.col(\"postcode\") >= lower) & (F.col(\"postcode\") <= upper))\n",
    "\n",
    "# Apply condition\n",
    "customer_details_abs = customer_details_abs.withColumn('is_po_box', po_box_condition)\n",
    "\n",
    "# Confirm that transactions with no associated ABS data delivers to a PO box\n",
    "customer_details_abs.filter(\"sa2_code IS NOT NULL AND is_po_box IS NULL\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Specify column order to see features better\n",
    "col_order = [\"order_id\", \"user_id\",\"merchant_abn\", \"order_datetime\", \"dollar_value\", \n",
    "              \"postcode\", \"merchant_fraud\", \"consumer_fraud\",\"weekly_personal_disposable\",\n",
    "              \"median_total_household_income\", \"median_total_family_income\"]\n",
    "\n",
    "# Save changes to \"all_details\"\n",
    "customer_details_abs.select(*col_order, *(set(customer_details_abs.columns) ^ set(col_order)))\\\n",
    "    .write.mode('overwrite').parquet('../data/curated/all_details/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_id</th><th>user_id</th><th>merchant_abn</th><th>order_datetime</th><th>dollar_value</th><th>postcode</th><th>merchant_fraud</th><th>consumer_fraud</th><th>weekly_personal_disposable</th><th>median_total_household_income</th><th>median_total_family_income</th><th>avg_household_size</th><th>sa2_code</th><th>sa2_name</th><th>is_po_box</th><th>median_age</th></tr>\n",
       "<tr><td>45030f06-09fc-4f3...</td><td>22957</td><td>89109402284</td><td>2022-02-12</td><td>43415.16340467725</td><td>3178</td><td>29.07408314204997</td><td>82.79065699075498</td><td>559.9299353115772</td><td>2083.0</td><td>2305.0</td><td>2.8</td><td>211011256</td><td>Rowville - Central</td><td>false</td><td>41.0</td></tr>\n",
       "<tr><td>57ed6f9a-1b54-466...</td><td>22957</td><td>75454398468</td><td>2022-03-01</td><td>3052.23803054996</td><td>3178</td><td>0.0</td><td>0.0</td><td>559.9299353115772</td><td>2083.0</td><td>2305.0</td><td>2.8</td><td>211011256</td><td>Rowville - Central</td><td>false</td><td>41.0</td></tr>\n",
       "<tr><td>aea838f0-5f39-487...</td><td>22957</td><td>24015576448</td><td>2022-06-08</td><td>2976.0698327959976</td><td>3178</td><td>0.0</td><td>0.0</td><td>559.9299353115772</td><td>2083.0</td><td>2305.0</td><td>2.8</td><td>211011256</td><td>Rowville - Central</td><td>false</td><td>41.0</td></tr>\n",
       "<tr><td>4616274a-a016-43e...</td><td>22957</td><td>11848576000</td><td>2022-10-11</td><td>2832.1977785469935</td><td>3178</td><td>0.0</td><td>0.0</td><td>559.9299353115772</td><td>2083.0</td><td>2305.0</td><td>2.8</td><td>211011256</td><td>Rowville - Central</td><td>false</td><td>41.0</td></tr>\n",
       "<tr><td>74038823-d581-4e6...</td><td>22957</td><td>35906534450</td><td>2022-04-16</td><td>2135.9475370548244</td><td>3178</td><td>0.0</td><td>0.0</td><td>559.9299353115772</td><td>2083.0</td><td>2305.0</td><td>2.8</td><td>211011256</td><td>Rowville - Central</td><td>false</td><td>41.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-------+------------+--------------+------------------+--------+-----------------+-----------------+--------------------------+-----------------------------+--------------------------+------------------+---------+------------------+---------+----------+\n",
       "|            order_id|user_id|merchant_abn|order_datetime|      dollar_value|postcode|   merchant_fraud|   consumer_fraud|weekly_personal_disposable|median_total_household_income|median_total_family_income|avg_household_size| sa2_code|          sa2_name|is_po_box|median_age|\n",
       "+--------------------+-------+------------+--------------+------------------+--------+-----------------+-----------------+--------------------------+-----------------------------+--------------------------+------------------+---------+------------------+---------+----------+\n",
       "|45030f06-09fc-4f3...|  22957| 89109402284|    2022-02-12| 43415.16340467725|    3178|29.07408314204997|82.79065699075498|         559.9299353115772|                       2083.0|                    2305.0|               2.8|211011256|Rowville - Central|    false|      41.0|\n",
       "|57ed6f9a-1b54-466...|  22957| 75454398468|    2022-03-01|  3052.23803054996|    3178|              0.0|              0.0|         559.9299353115772|                       2083.0|                    2305.0|               2.8|211011256|Rowville - Central|    false|      41.0|\n",
       "|aea838f0-5f39-487...|  22957| 24015576448|    2022-06-08|2976.0698327959976|    3178|              0.0|              0.0|         559.9299353115772|                       2083.0|                    2305.0|               2.8|211011256|Rowville - Central|    false|      41.0|\n",
       "|4616274a-a016-43e...|  22957| 11848576000|    2022-10-11|2832.1977785469935|    3178|              0.0|              0.0|         559.9299353115772|                       2083.0|                    2305.0|               2.8|211011256|Rowville - Central|    false|      41.0|\n",
       "|74038823-d581-4e6...|  22957| 35906534450|    2022-04-16|2135.9475370548244|    3178|              0.0|              0.0|         559.9299353115772|                       2083.0|                    2305.0|               2.8|211011256|Rowville - Central|    false|      41.0|\n",
       "+--------------------+-------+------------+--------------+------------------+--------+-----------------+-----------------+--------------------------+-----------------------------+--------------------------+------------------+---------+------------------+---------+----------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = spark.read.parquet('../data/curated/all_details/')\n",
    "\n",
    "# view sample of a random user's transaction history\n",
    "temp.filter(F.col('user_id')==22957).orderBy('dollar_value', ascending=False).limit(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
